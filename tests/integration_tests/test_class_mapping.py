"""Integration test to verify all model classes match mapping.json.

This test validates that all AUTOSAR model classes are defined at the
expected package paths as specified in docs/requirements/mapping.json.

For example:
    BswModuleDescription should be defined as:
    armodel.models.M2.AUTOSARTemplates.BswModuleTemplate.BswOverview
"""
import json
import importlib
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple

import pytest


def generate_detailed_report(
    results_by_type: Dict[str, Dict],
    output_path: Path
) -> None:
    """Generate a detailed markdown report of class mapping verification.

    Args:
        results_by_type: Dictionary with test results for each type category
        output_path: Path where the report should be saved
    """
    lines = []
    lines.append("# Class Mapping Verification Report\n")
    lines.append("*This report is automatically generated by "
                 "test_class_mapping.py*\n")

    # Overall summary
    total_types = sum(s['total'] for s in results_by_type.values())
    total_passed = sum(s['passed'] for s in results_by_type.values())
    total_failed = sum(len(s['failures']) for s in results_by_type.values())

    lines.append("## Overall Summary\n")
    lines.append(f"- **Total Types**: {total_types}")
    lines.append(f"- **Passed**: {total_passed} ({total_passed/total_types*100:.1f}%)")
    lines.append(f"- **Failed**: {total_failed} ({total_failed/total_types*100:.1f}%)")
    lines.append("")


def generate_detailed_report_with_status(
    results_by_type: Dict[str, Dict],
    output_path: Path
) -> None:
    """Generate a detailed markdown report including not implemented classes.

    Args:
        results_by_type: Dictionary with test results including not_implemented
        output_path: Path where the report should be saved
    """
    lines = []
    lines.append("# Class Mapping Verification Report\n")
    lines.append("*This report is automatically generated by test_class_mapping.py*")
    lines.append("*Only classes that exist in the codebase are verified against mapping.json*\n")

    # Overall summary
    total_types = sum(s['total'] for s in results_by_type.values())
    total_verified = sum(s.get('verified', 0) for s in results_by_type.values())
    total_passed = sum(s['passed'] for s in results_by_type.values())
    total_failures = sum(len(s['failures']) for s in results_by_type.values())
    total_not_impl = sum(len(s.get('not_implemented', [])) for s in results_by_type.values())

    lines.append("## Overall Summary\n")
    lines.append(f"- **Total Types in mapping.json**: {total_types}")
    lines.append(f"- **Existing in Codebase**: {total_verified} ({total_verified/total_types*100:.1f}%)")
    lines.append(f"- **Verified Correct Location**: {total_passed} ({total_passed/total_types*100:.1f}%)")
    lines.append(f"- **Wrong Location (Fixable)**: {total_failures}")
    lines.append(f"- **Not Implemented (Deferred)**: {total_not_impl}")
    lines.append("")

    # Summary by type
    lines.append("## Summary by Type\n")
    for type_cat, stats in results_by_type.items():
        total = stats['total']
        verified = stats.get('verified', 0)
        passed = stats['passed']
        failed = len(stats['failures'])
        not_impl = len(stats.get('not_implemented', []))

        lines.append(f"### {type_cat}")
        lines.append(f"- **Total**: {total}")
        lines.append(f"- **Existing**: {verified} ({verified/total*100:.1f}%)")
        lines.append(f"- **Passed**: {passed} ({passed/total*100:.1f}%)")
        lines.append(f"- **Wrong Location**: {failed}")
        lines.append(f"- **Not Implemented**: {not_impl}")
        lines.append("")

    # Detailed failures section
    lines.append("## Wrong Location (Fixable)\n")
    lines.append("*Classes that exist in the codebase but are not at the expected mapped location*\n")

    has_failures = False
    for type_cat, stats in results_by_type.items():
        failures = stats['failures']
        if not failures:
            continue

        has_failures = True
        lines.append(f"### {type_cat} ({len(failures)} classes)\n")

        # Group by error type
        module_not_found = []
        class_not_found = []

        for name, error in failures:
            if "No module named" in error or "Failed to import module" in error:
                module_not_found.append((name, error))
            elif "not found in module" in error:
                class_not_found.append((name, error))
            else:
                module_not_found.append((name, error))

        if module_not_found:
            lines.append(f"#### Module Not Found ({len(module_not_found)})\n")
            lines.append("| Class Name | Expected Module |")
            lines.append("|------------|-----------------|")
            for name, error in sorted(module_not_found):
                # Extract module path from error
                if "'" in error:
                    module = error.split("'")[1]
                else:
                    module = "Unknown"
                lines.append(f"| `{name}` | `{module}` |")
            lines.append("")

        if class_not_found:
            lines.append(f"#### Class Not Found in Module ({len(class_not_found)})\n")
            lines.append("| Class Name | Expected Module |")
            lines.append("|------------|-----------------|")
            for name, error in sorted(class_not_found):
                # Error format: "Class 'X' not found in module 'Y'"
                # Need to extract the module path (the 2nd quoted string)
                if "not found in module '" in error:
                    parts = error.split("not found in module '")
                    if len(parts) > 1:
                        module = parts[1].rstrip("'")
                    else:
                        module = "Unknown"
                elif "'" in error:
                    # Fallback: try to get the last quoted string (module path)
                    quotes = error.split("'")
                    module = quotes[-2] if len(quotes) >= 2 else "Unknown"
                else:
                    module = "Unknown"
                lines.append(f"| `{name}` | `{module}` |")
            lines.append("")

    if not has_failures:
        lines.append("*No classes in wrong location!* [OK]\n")

    # Not implemented section
    lines.append("## Not Implemented (Deferred)\n")
    lines.append("*Classes in mapping.json that haven't been implemented yet*\n")

    has_not_impl = False
    for type_cat, stats in results_by_type.items():
        not_impl = stats.get('not_implemented', [])
        if not not_impl:
            continue

        has_not_impl = True
        lines.append(f"### {type_cat} ({len(not_impl)} classes)\n")
        lines.append("| Class Name | Expected Module |")
        lines.append("|------------|-----------------|")
        for name, module_path in sorted(not_impl):
            # Format module path for display
            if module_path.startswith("armodel.models."):
                display_module = module_path.replace("armodel.models.", "")
            else:
                display_module = module_path
            lines.append(f"| `{name}` | `{display_module}` |")
        lines.append("")

    if not has_not_impl:
        lines.append("*All classes have been implemented!* [OK]\n")

    # Write the report
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"\nDetailed report saved to: {output_path}")


def convert_package_path_to_module(package_path: str) -> str:
    """Convert AUTOSAR package path to Python module path.

    Args:
        package_path: AUTOSAR package path (e.g., "M2::AUTOSARTemplates::BswModuleTemplate")

    Returns:
        Python module path (e.g., "armodel.models.M2.AUTOSARTemplates.BswModuleTemplate")
    """
    # Replace '::' with '.' and prepend base module path
    return f"armodel.models.{package_path.replace('::', '.')}"


def load_mapping_json() -> Dict:
    """Load the mapping.json file.

    Returns:
        Dictionary containing the mapping data with 'types' key
    """
    mapping_path = Path(__file__).parent.parent.parent / "docs" / "requirements" / "mapping.json"
    with open(mapping_path, 'r') as f:
        return json.load(f)


def load_existing_classes() -> Dict[str, set]:
    """Load existing classes from existing_classes.json.

    Returns:
        Dictionary mapping module paths to sets of class names
    """
    existing_path = Path(__file__).parent.parent.parent / "reports" / "existing_classes.json"

    if not existing_path.exists():
        print(f"Warning: {existing_path} not found. Run scan_existing_classes.py first.")
        return {}

    with open(existing_path, 'r') as f:
        data = json.load(f)

    return data.get('classes', {})


def verify_class_exists(module_path: str, class_name: str) -> Tuple[bool, str]:
    """Verify that a class exists at the specified module path.

    Args:
        module_path: Full Python module path (e.g., "armodel.models.M2.AUTOSARTemplates.BswModuleTemplate.BswOverview")
        class_name: Name of the class to verify (e.g., "BswModuleDescription")

    Returns:
        Tuple of (success, error_message)
    """
    try:
        module = importlib.import_module(module_path)
        if hasattr(module, class_name):
            return True, ""
        else:
            return False, f"Class '{class_name}' not found in module '{module_path}'"
    except ImportError as e:
        return False, f"Failed to import module '{module_path}': {e}"
    except Exception as e:
        return False, f"Unexpected error importing '{module_path}': {e}"


def is_class_in_existing_classes(
    class_name: str,
    module_path: str,
    existing_classes: Dict[str, set]
) -> bool:
    """Check if a class exists in the scanned existing classes.

    Args:
        class_name: Name of the class to check
        module_path: Expected module path for the class
        existing_classes: Dictionary from load_existing_classes()

    Returns:
        True if the class exists in the codebase, False otherwise
    """
    # Check if class exists at the expected module path
    if module_path in existing_classes and class_name in existing_classes[module_path]:
        return True

    # Check if class exists anywhere in the codebase
    for mod_path, class_list in existing_classes.items():
        if class_name in class_list:
            return True

    return False


class TestClassMapping:
    """Test suite for verifying model class mappings against mapping.json.

    Only verifies classes that exist in the codebase. Classes that haven't
    been implemented yet are tracked separately in the report as "Not Implemented".

    These tests require existing_classes.json. To run them:
    1. Generate existing_classes.json: python scripts/scan_existing_classes.py
    2. Run tests: pytest tests/integration_tests/test_class_mapping.py -v
    """

    @pytest.fixture
    def mapping_data(self) -> Dict:
        """Load mapping.json data."""
        return load_mapping_json()

    @pytest.fixture
    def all_types(self, mapping_data: Dict) -> List[Dict]:
        """Get all type entries from mapping.json."""
        return mapping_data.get('types', [])

    @pytest.fixture
    def existing_classes(self) -> Dict[str, set]:
        """Load existing classes from scan."""
        return load_existing_classes()

    def test_all_classes_mapped(self, all_types: List[Dict], existing_classes: Dict[str, set]):
        """Verify all Class types are correctly mapped and importable.

        This test verifies that:
        1. Each Class entry in mapping.json exists at the expected module path
        2. The class can be successfully imported

        Note: This test is skipped in CI if existing_classes.json is not available.
        """
        # Skip test if existing_classes.json is not available (e.g., in CI)
        if not existing_classes:
            pytest.skip("existing_classes.json not found. Run 'python scripts/scan_existing_classes.py' first.")

        classes = [t for t in all_types if t.get('type') == 'Class']
        total_classes = len(classes)

        print(f"\n=== Testing {total_classes} Class types ===")

        failures = []
        passed = 0

        for idx, type_entry in enumerate(classes, 1):
            class_name = type_entry.get('name')
            package_path = type_entry.get('package_path')

            if not class_name or not package_path:
                failures.append((class_name or "Unknown",
                               "Missing name or package_path"))
                continue

            module_path = convert_package_path_to_module(package_path)
            success, error_msg = verify_class_exists(module_path, class_name)

            if success:
                passed += 1
                if idx % 100 == 0:
                    print(f"  Progress: {idx}/{total_classes} classes verified")
            else:
                failures.append((class_name, error_msg))

        # Print summary
        print(f"\nResults: {passed}/{total_classes} classes verified successfully")
        if failures:
            print(f"\n=== Failures ({len(failures)}) ===")
            for class_name, error in failures[:10]:  # Show first 10 failures
                print(f"  - {class_name}: {error}")
            if len(failures) > 10:
                print(f"  ... and {len(failures) - 10} more failures")

            # Generate detailed report for classes
            results_by_type = {
                'Class': {'total': total_classes, 'passed': passed, 'failures': failures}
            }
            report_path = Path(__file__).parent.parent.parent / "reports" / "class_mapping_classes_report.md"
            generate_detailed_report(results_by_type, report_path)

        # Assert all classes were found
        assert len(failures) == 0, (
            f"\n{len(failures)} classes failed to match mapping:\n" +
            "\n".join(f"  - {name}: {err}" for name, err in failures[:20])
        )

    def test_all_enumerations_mapped(self, all_types: List[Dict], existing_classes: Dict[str, set]):
        """Verify all Enumeration types are correctly mapped and importable.

        This test verifies that:
        1. Each Enumeration entry in mapping.json exists at the expected module path
        2. The enumeration can be successfully imported

        Note: This test is skipped in CI if existing_classes.json is not available.
        """
        # Skip test if existing_classes.json is not available (e.g., in CI)
        if not existing_classes:
            pytest.skip("existing_classes.json not found. Run 'python scripts/scan_existing_classes.py' first.")

        enumerations = [t for t in all_types if t.get('type') == 'Enumeration']
        total_enums = len(enumerations)

        print(f"\n=== Testing {total_enums} Enumeration types ===")

        failures = []
        passed = 0

        for idx, type_entry in enumerate(enumerations, 1):
            enum_name = type_entry.get('name')
            package_path = type_entry.get('package_path')

            if not enum_name or not package_path:
                failures.append((enum_name or "Unknown",
                               "Missing name or package_path"))
                continue

            module_path = convert_package_path_to_module(package_path)
            success, error_msg = verify_class_exists(module_path, enum_name)

            if success:
                passed += 1
                if idx % 100 == 0:
                    print(f"  Progress: {idx}/{total_enums} enumerations verified")
            else:
                failures.append((enum_name, error_msg))

        # Print summary
        print(f"\nResults: {passed}/{total_enums} enumerations verified successfully")
        if failures:
            print(f"\n=== Failures ({len(failures)}) ===")
            for enum_name, error in failures[:10]:  # Show first 10 failures
                print(f"  - {enum_name}: {error}")
            if len(failures) > 10:
                print(f"  ... and {len(failures) - 10} more failures")

            # Generate detailed report for enumerations
            results_by_type = {
                'Enumeration': {'total': total_enums, 'passed': passed, 'failures': failures}
            }
            report_path = Path(__file__).parent.parent.parent / "reports" / "class_mapping_enums_report.md"
            generate_detailed_report(results_by_type, report_path)

        # Assert all enumerations were found
        assert len(failures) == 0, (
            f"\n{len(failures)} enumerations failed to match mapping:\n" +
            "\n".join(f"  - {name}: {err}" for name, err in failures[:20])
        )

    def test_all_primitives_mapped(self, all_types: List[Dict], existing_classes: Dict[str, set]):
        """Verify all Primitive types are correctly mapped and importable.

        This test verifies that:
        1. Each Primitive entry in mapping.json exists at the expected module path
        2. The primitive type can be successfully imported

        Note: This test is skipped in CI if existing_classes.json is not available.
        """
        # Skip test if existing_classes.json is not available (e.g., in CI)
        if not existing_classes:
            pytest.skip("existing_classes.json not found. Run 'python scripts/scan_existing_classes.py' first.")

        primitives = [t for t in all_types if t.get('type') == 'Primitive']
        total_primitives = len(primitives)

        print(f"\n=== Testing {total_primitives} Primitive types ===")

        failures = []
        passed = 0

        for idx, type_entry in enumerate(primitives, 1):
            primitive_name = type_entry.get('name')
            package_path = type_entry.get('package_path')

            if not primitive_name or not package_path:
                failures.append((primitive_name or "Unknown",
                               "Missing name or package_path"))
                continue

            module_path = convert_package_path_to_module(package_path)
            success, error_msg = verify_class_exists(module_path, primitive_name)

            if success:
                passed += 1
            else:
                failures.append((primitive_name, error_msg))

        # Print summary
        print(f"\nResults: {passed}/{total_primitives} primitives verified successfully")
        if failures:
            print(f"\n=== Failures ({len(failures)}) ===")
            for primitive_name, error in failures[:10]:  # Show first 10 failures
                print(f"  - {primitive_name}: {error}")
            if len(failures) > 10:
                print(f"  ... and {len(failures) - 10} more failures")

            # Generate detailed report for primitives
            results_by_type = {
                'Primitive': {'total': total_primitives, 'passed': passed, 'failures': failures}
            }
            report_path = Path(__file__).parent.parent.parent / "reports" / "class_mapping_primitives_report.md"
            generate_detailed_report(results_by_type, report_path)

        # Assert all primitives were found
        assert len(failures) == 0, (
            f"\n{len(failures)} primitives failed to match mapping:\n" +
            "\n".join(f"  - {name}: {err}" for name, err in failures[:20])
        )

    def test_all_types_combined(
        self,
        all_types: List[Dict],
        existing_classes: Dict[str, set]
    ):
        """Comprehensive test verifying all types (Class, Enumeration, Primitive).

        This test provides a combined report of all type verification results.
        Only verifies classes that exist in the codebase. Unimplemented classes
        are tracked separately in the report.

        Note: This test is skipped in CI if existing_classes.json is not available.
        Run `python scripts/scan_existing_classes.py` first to generate it.
        """
        # Skip test if existing_classes.json is not available (e.g., in CI)
        if not existing_classes:
            pytest.skip("existing_classes.json not found. Run 'python scripts/scan_existing_classes.py' first.")

        total_types = len(all_types)
        print(f"\n=== Comprehensive Test: {total_types} total types in mapping.json ===")
        print(f"Existing classes in codebase: {sum(len(c) for c in existing_classes.values())}")

        results_by_type = {
            'Class': {
                'total': 0,
                'verified': 0,
                'passed': 0,
                'failures': [],
                'not_implemented': []
            },
            'Enumeration': {
                'total': 0,
                'verified': 0,
                'passed': 0,
                'failures': [],
                'not_implemented': []
            },
            'Primitive': {
                'total': 0,
                'verified': 0,
                'passed': 0,
                'failures': [],
                'not_implemented': []
            }
        }

        for type_entry in all_types:
            type_category = type_entry.get('type', 'Unknown')
            type_name = type_entry.get('name')
            package_path = type_entry.get('package_path')

            if type_category not in results_by_type:
                continue

            results_by_type[type_category]['total'] += 1

            if not type_name or not package_path:
                results_by_type[type_category]['failures'].append(
                    (type_name or "Unknown", "Missing name or package_path")
                )
                continue

            module_path = convert_package_path_to_module(package_path)

            # Check if this class exists in the codebase
            if not is_class_in_existing_classes(type_name, module_path, existing_classes):
                # Class not implemented yet - track separately
                results_by_type[type_category]['not_implemented'].append(
                    (type_name, module_path)
                )
                continue

            # Class exists - verify it's at the correct location
            results_by_type[type_category]['verified'] += 1
            success, error_msg = verify_class_exists(module_path, type_name)

            if success:
                results_by_type[type_category]['passed'] += 1
            else:
                results_by_type[type_category]['failures'].append(
                    (type_name, error_msg)
                )

        # Print comprehensive summary
        print("\n=== Summary by Type ===")
        for type_cat, stats in results_by_type.items():
            total = stats['total']
            verified = stats['verified']
            passed = stats['passed']
            failures_count = len(stats['failures'])
            not_impl_count = len(stats['not_implemented'])

            print(f"\n{type_cat}:")
            print(f"  Total in mapping.json: {total}")
            print(f"  Existing in codebase: {verified} ({verified/total*100:.1f}%)")
            print(f"  Verified correct location: {passed} ({passed/total*100:.1f}%)")
            print(f"  Wrong location: {failures_count}")
            print(f"  Not implemented: {not_impl_count}")

        # Calculate overall statistics
        total_passed = sum(s['passed'] for s in results_by_type.values())
        total_verified = sum(s['verified'] for s in results_by_type.values())
        total_failures = sum(len(s['failures']) for s in results_by_type.values())
        total_not_impl = sum(len(s['not_implemented']) for s in results_by_type.values())

        print(f"\n=== Overall Results ===")
        print(f"Total in mapping.json: {total_types}")
        print(f"Existing in codebase: {total_verified} ({total_verified/total_types*100:.1f}%)")
        print(f"Verified correct location: {total_passed} ({total_passed/total_types*100:.1f}%)")
        print(f"Wrong location (fixable): {total_failures}")
        print(f"Not implemented (deferred): {total_not_impl}")

        # Generate detailed report
        report_path = Path(__file__).parent.parent.parent / "reports" / "class_mapping_report.md"
        generate_detailed_report_with_status(results_by_type, report_path)

        # Collect only failures for classes that exist (wrong location)
        all_failures = []
        for type_cat, stats in results_by_type.items():
            for name, error in stats['failures']:
                all_failures.append((f"[{type_cat}] {name}", error))

        # Assert all existing classes are in correct location
        # (We don't fail on not implemented classes)
        assert len(all_failures) == 0, (
            f"\n{len(all_failures)} existing classes are in wrong location:\n"
            f"See detailed report at: {report_path}\n"
            "\n".join(f"  {name}: {err}" for name, err in all_failures[:20])
        )


def test_example_bsw_module_description():
    """Example test showing how to verify a specific class.

    This serves as documentation and validation of the test approach.
    """
    # Example from the user request:
    # BswModuleDescription should be at:
    # armodel.models.M2.AUTOSARTemplates.BswModuleTemplate.BswOverview

    class_name = "BswModuleDescription"
    package_path = "M2::AUTOSARTemplates::BswModuleTemplate::BswOverview"
    expected_module = convert_package_path_to_module(package_path)

    success, error_msg = verify_class_exists(expected_module, class_name)

    assert success, f"Failed to verify {class_name}: {error_msg}"
    assert expected_module == "armodel.models.M2.AUTOSARTemplates.BswModuleTemplate.BswOverview"
